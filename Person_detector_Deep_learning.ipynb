{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HelloPython.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1IzpDtYWfursCxwCxFcpGwv8-1NHjMlle",
      "authorship_tag": "ABX9TyMIJnO+bM47hfJycJO/PEb+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lamtranBKHN/AGV-2.0/blob/master/Person_detector_Deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQmwN_0edfcU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "96dc9053-a017-4629-e52d-9571a59c1363"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTGOqgA4fu0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "24bef66c-1c6b-4567-a2bd-acacfbb2cc9c"
      },
      "source": [
        "!pip install mtcnn"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.18.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzpxWbEQjIgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from imutils import paths\n",
        "from keras.applications import VGG16\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.applications import VGG16\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ljvsmP5dYrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 150\n",
        "\n",
        "file_list = []\n",
        "class_list = []\n",
        "\n",
        "DATADIR = \"drive/My Drive/data\"\n",
        "\n",
        "# All the categories neural network will detect\n",
        "CATEGORIES = [\"Den_Vau\", \"Avicii\", \"Adele\", \"Charlie_Puth\", \"Adam_Levine\"]\n",
        "\n",
        "# Checking or all images in the data folder\n",
        "for category in CATEGORIES :\n",
        "    path = os.path.join(DATADIR, category)\n",
        "    for img in os.listdir(path):\n",
        "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES :\n",
        "        path = os.path.join(DATADIR, category)\n",
        "        class_num = CATEGORIES.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try :\n",
        "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "                training_data.append([new_array, class_num])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "create_training_data()\n",
        "random.shuffle(training_data)\n",
        "\n",
        "X = [] #features\n",
        "y = [] #labels\n",
        "\n",
        "for features, label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "    \n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wRK5tUOgHL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the files containing all the information about your model\n",
        "pickle_out = open(\"X.pickle\", \"wb\")\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"y.pickle\", \"wb\")\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_in = open(\"X.pickle\", \"rb\")\n",
        "X = pickle.load(pickle_in)\n",
        "\n",
        "# Opening the files about data\n",
        "X = pickle.load(open(\"X.pickle\", \"rb\"))\n",
        "y = pickle.load(open(\"y.pickle\", \"rb\"))\n",
        "\n",
        "# normalizing data (a pixel goes from 0 to 255)\n",
        "X = X/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r3S6vHat_eY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the VGG16 network\n",
        "baseModel = VGG16(weights='imagenet', include_top=False,  \n",
        "             input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "\n",
        "# Build more layers\n",
        "fcHead = baseModel.output\n",
        "\n",
        "# Flatten before FCs\n",
        "fcHead = Flatten()(fcHead)\n",
        "\n",
        "# Add FC\n",
        "fcHead = Dense(256, activation='relu')(fcHead)\n",
        "fcHead = Dropout(0.5)(fcHead)\n",
        "\n",
        "# Output layer with softmax activation\n",
        "fcHead = Dense(5, activation='softmax')(fcHead)\n",
        "\n",
        "# Build model by conect ConvNet of VGG16 and fcHead\n",
        "model = model = Model(inputs=baseModel.input, outputs=fcHead)\n",
        "\n",
        "# freeze VGG model\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compiling the model using some basic parameters\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Training the model.\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "history = model.fit(X, y, batch_size=32, epochs=20, validation_split=0.1)\n",
        "\n",
        "# Printing a graph showing the accuracy changes during the training phase\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# unfreeze some last CNN layer:\n",
        "for layer in baseModel.layers[15:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Compiling the model using some basic parameters\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Training the model.\n",
        "history = model.fit(X, y, batch_size=32, epochs=30, validation_split=0.1)\n",
        "\n",
        "# Saving the model\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file :\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"model2.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "model.save('CNN2.model')\n",
        "\n",
        "# Printing a graph showing the accuracy changes during the training phase\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqqa5BxNuD1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare(filename, required_size=(IMG_SIZE, IMG_SIZE)):\n",
        "    # load image from file\n",
        "    pixels = pyplot.imread(filename)\n",
        "    # create the detector, using default weights\n",
        "    detector = MTCNN()\n",
        "    # detect faces in the image\n",
        "    results = detector.detect_faces(pixels)\n",
        "    # extract the bounding box from the first face\n",
        "    x1, y1, width, height = results[0]['box']\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "    # extract the face\n",
        "    face = pixels[y1:y2, x1:x2]\n",
        "    # resize pixels to the model size\n",
        "    image = Image.fromarray(face)\n",
        "    image = image.resize(required_size)\n",
        "    face_array = asarray(image)\n",
        "    # face_array = cv2.cvtColor(face_array, cv2.COLOR_BGR2GRAY)\n",
        "    new_array = cv2.resize(face_array, (IMG_SIZE, IMG_SIZE))\n",
        "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "model = tf.keras.models.load_model(\"CNN2.model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DXK9M0CuHEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = prepare(\"test_Den1.jpg\")\n",
        "prediction = model.predict([image])\n",
        "prediction = list(prediction[0])\n",
        "print(CATEGORIES[prediction.index(max(prediction))])\n",
        "show = cv2.imread('test_Den1.jpg', 1)\n",
        "show = show[..., ::-1]\n",
        "plt.imshow(show) \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}