{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Dectector12.4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Dl2zCKnrta842I0zUZXoC6_-tpmJy97_",
      "authorship_tag": "ABX9TyOWUeejxagjUQP2U3Nz4Ney",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lamtranBKHN/AGV-2.0/blob/master/Face_Dectector12_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXOhlK_Zg6WL",
        "colab_type": "code",
        "outputId": "b4de1c06-18e1-46e7-9b7f-bbfdc2f02c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from imutils import paths\n",
        "from keras.applications import VGG16\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.applications import VGG16\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W0WL59Jg6YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "file_list = []\n",
        "class_list = []\n",
        "\n",
        "\n",
        "DATADIR = \"data\"\n",
        "\n",
        "# All the categories neural network will detect\n",
        "CATEGORIES = [\"Avicii\", \"Charlie_Puth\",\"Den_Vau\",\"Adam_Levine\",\"Adele\"]\n",
        "\n",
        "# Checking or all images in the data folder\n",
        "for category in CATEGORIES :\n",
        "    path = os.path.join(DATADIR, category)\n",
        "    for img in os.listdir(path):\n",
        "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES :\n",
        "        path = os.path.join(DATADIR, category)\n",
        "        class_num = CATEGORIES.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try :\n",
        "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "                training_data.append([new_array, class_num])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "create_training_data()\n",
        "random.shuffle(training_data)\n",
        "\n",
        "X = [] #features\n",
        "y = [] #labels\n",
        "\n",
        "for features, label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "    \n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)   \n",
        "# Creating the files containing all the information about your model\n",
        "pickle_out = open(\"X.pickle\", \"wb\")\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"y.pickle\", \"wb\")\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_in = open(\"X.pickle\", \"rb\")\n",
        "X = pickle.load(pickle_in)\n",
        "\n",
        "# Opening the files about data\n",
        "X = pickle.load(open(\"X.pickle\", \"rb\"))\n",
        "y = pickle.load(open(\"y.pickle\", \"rb\"))\n",
        "\n",
        "# normalizing data (a pixel goes from 0 to 255)\n",
        "X = X/255.0         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SefNi9I3g6a1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from keras.utils import to_categorical\n",
        "#y = to_categorical(y)\n",
        "# Load model VGG 16 của ImageNet dataset, include_top=False để bỏ phần Fully connected lay\n",
        "baseModel = VGG16(weights='imagenet', include_top=False, \\\n",
        "                  input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "# Buil layer\n",
        "fcHead = baseModel.output\n",
        "# Flatten \n",
        "fcHead = Flatten()(fcHead)\n",
        "# Add FC\n",
        "fcHead = Dense(256, activation='relu')(fcHead)\n",
        "fcHead = Dropout(0.5)(fcHead)\n",
        "# Output layer with softmax activation\n",
        "fcHead = Dense(5, activation='softmax')(fcHead)\n",
        "# modle\n",
        "model = model = Model(inputs=baseModel.input, outputs=fcHead)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbufHZs9g6de",
        "colab_type": "code",
        "outputId": "c750f3c0-97cd-462f-a094-b9a8dbefcd31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss = \"sparse_categorical_crossentropy\", \n",
        "                    optimizer = SGD(lr=1e-5, momentum=0.9), \n",
        "                    metrics=[\"accuracy\"])\n",
        "# Training the model.\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "history = model.fit(X, y, batch_size=32, epochs=500, validation_split=0.1)\n",
        "\n",
        "# Saving the model\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file :\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"model2.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "model.save('CNN2.model')\n",
        "\n",
        "# Printing a graph showing the accuracy changes during the training phase\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1636 samples, validate on 182 samples\n",
            "Epoch 1/500\n",
            "1636/1636 [==============================] - 17s 10ms/step - loss: 1.8310 - accuracy: 0.2372 - val_loss: 1.4627 - val_accuracy: 0.4231\n",
            "Epoch 2/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 1.5440 - accuracy: 0.3240 - val_loss: 1.3289 - val_accuracy: 0.5769\n",
            "Epoch 3/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 1.3888 - accuracy: 0.4303 - val_loss: 1.2207 - val_accuracy: 0.6648\n",
            "Epoch 4/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 1.2644 - accuracy: 0.5098 - val_loss: 1.1262 - val_accuracy: 0.6813\n",
            "Epoch 5/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 1.1447 - accuracy: 0.5654 - val_loss: 1.0377 - val_accuracy: 0.7253\n",
            "Epoch 6/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 1.0478 - accuracy: 0.6339 - val_loss: 0.9408 - val_accuracy: 0.7363\n",
            "Epoch 7/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.9470 - accuracy: 0.6626 - val_loss: 0.8580 - val_accuracy: 0.8132\n",
            "Epoch 8/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.8674 - accuracy: 0.7042 - val_loss: 0.7631 - val_accuracy: 0.8077\n",
            "Epoch 9/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.7720 - accuracy: 0.7445 - val_loss: 0.6753 - val_accuracy: 0.8462\n",
            "Epoch 10/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.7097 - accuracy: 0.7598 - val_loss: 0.5927 - val_accuracy: 0.8571\n",
            "Epoch 11/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.6050 - accuracy: 0.8111 - val_loss: 0.5202 - val_accuracy: 0.8901\n",
            "Epoch 12/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.5221 - accuracy: 0.8325 - val_loss: 0.4544 - val_accuracy: 0.9011\n",
            "Epoch 13/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.4948 - accuracy: 0.8478 - val_loss: 0.3933 - val_accuracy: 0.9121\n",
            "Epoch 14/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.4197 - accuracy: 0.8759 - val_loss: 0.3442 - val_accuracy: 0.9286\n",
            "Epoch 15/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.3746 - accuracy: 0.8833 - val_loss: 0.2974 - val_accuracy: 0.9451\n",
            "Epoch 16/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.3139 - accuracy: 0.9040 - val_loss: 0.2615 - val_accuracy: 0.9451\n",
            "Epoch 17/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.2872 - accuracy: 0.9187 - val_loss: 0.2296 - val_accuracy: 0.9560\n",
            "Epoch 18/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.2598 - accuracy: 0.9230 - val_loss: 0.2013 - val_accuracy: 0.9560\n",
            "Epoch 19/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.2325 - accuracy: 0.9383 - val_loss: 0.1847 - val_accuracy: 0.9560\n",
            "Epoch 20/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.2303 - accuracy: 0.9285 - val_loss: 0.1609 - val_accuracy: 0.9670\n",
            "Epoch 21/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.1966 - accuracy: 0.9425 - val_loss: 0.1570 - val_accuracy: 0.9615\n",
            "Epoch 22/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.1855 - accuracy: 0.9383 - val_loss: 0.1348 - val_accuracy: 0.9725\n",
            "Epoch 23/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.1604 - accuracy: 0.9554 - val_loss: 0.1202 - val_accuracy: 0.9835\n",
            "Epoch 24/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.1494 - accuracy: 0.9529 - val_loss: 0.1213 - val_accuracy: 0.9670\n",
            "Epoch 25/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.1508 - accuracy: 0.9505 - val_loss: 0.1041 - val_accuracy: 0.9835\n",
            "Epoch 26/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.1417 - accuracy: 0.9584 - val_loss: 0.0965 - val_accuracy: 0.9835\n",
            "Epoch 27/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.1025 - accuracy: 0.9737 - val_loss: 0.0883 - val_accuracy: 0.9835\n",
            "Epoch 28/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.1245 - accuracy: 0.9639 - val_loss: 0.0817 - val_accuracy: 0.9780\n",
            "Epoch 29/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0996 - accuracy: 0.9725 - val_loss: 0.0822 - val_accuracy: 0.9780\n",
            "Epoch 30/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.1011 - accuracy: 0.9731 - val_loss: 0.0734 - val_accuracy: 0.9835\n",
            "Epoch 31/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0923 - accuracy: 0.9762 - val_loss: 0.0714 - val_accuracy: 0.9780\n",
            "Epoch 32/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0880 - accuracy: 0.9762 - val_loss: 0.0656 - val_accuracy: 0.9835\n",
            "Epoch 33/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0757 - accuracy: 0.9823 - val_loss: 0.0672 - val_accuracy: 0.9835\n",
            "Epoch 34/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0766 - accuracy: 0.9804 - val_loss: 0.0586 - val_accuracy: 0.9835\n",
            "Epoch 35/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0771 - accuracy: 0.9768 - val_loss: 0.0578 - val_accuracy: 0.9835\n",
            "Epoch 36/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0695 - accuracy: 0.9829 - val_loss: 0.0618 - val_accuracy: 0.9780\n",
            "Epoch 37/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0591 - accuracy: 0.9872 - val_loss: 0.0507 - val_accuracy: 0.9835\n",
            "Epoch 38/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0592 - accuracy: 0.9859 - val_loss: 0.0517 - val_accuracy: 0.9835\n",
            "Epoch 39/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0631 - accuracy: 0.9841 - val_loss: 0.0510 - val_accuracy: 0.9835\n",
            "Epoch 40/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0664 - accuracy: 0.9811 - val_loss: 0.0539 - val_accuracy: 0.9835\n",
            "Epoch 41/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0595 - accuracy: 0.9841 - val_loss: 0.0451 - val_accuracy: 0.9835\n",
            "Epoch 42/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0473 - accuracy: 0.9884 - val_loss: 0.0406 - val_accuracy: 0.9835\n",
            "Epoch 43/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0554 - accuracy: 0.9835 - val_loss: 0.0394 - val_accuracy: 0.9890\n",
            "Epoch 44/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0476 - accuracy: 0.9902 - val_loss: 0.0407 - val_accuracy: 0.9780\n",
            "Epoch 45/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0460 - accuracy: 0.9859 - val_loss: 0.0476 - val_accuracy: 0.9835\n",
            "Epoch 46/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0407 - accuracy: 0.9896 - val_loss: 0.0433 - val_accuracy: 0.9890\n",
            "Epoch 47/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0440 - accuracy: 0.9884 - val_loss: 0.0439 - val_accuracy: 0.9890\n",
            "Epoch 48/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0371 - accuracy: 0.9914 - val_loss: 0.0411 - val_accuracy: 0.9890\n",
            "Epoch 49/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0342 - accuracy: 0.9933 - val_loss: 0.0378 - val_accuracy: 0.9890\n",
            "Epoch 50/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0316 - accuracy: 0.9921 - val_loss: 0.0367 - val_accuracy: 0.9890\n",
            "Epoch 51/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0324 - accuracy: 0.9921 - val_loss: 0.0421 - val_accuracy: 0.9835\n",
            "Epoch 52/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0377 - accuracy: 0.9902 - val_loss: 0.0393 - val_accuracy: 0.9890\n",
            "Epoch 53/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0322 - accuracy: 0.9908 - val_loss: 0.0340 - val_accuracy: 0.9890\n",
            "Epoch 54/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0281 - accuracy: 0.9939 - val_loss: 0.0347 - val_accuracy: 0.9890\n",
            "Epoch 55/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0283 - accuracy: 0.9921 - val_loss: 0.0330 - val_accuracy: 0.9890\n",
            "Epoch 56/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0222 - accuracy: 0.9976 - val_loss: 0.0351 - val_accuracy: 0.9890\n",
            "Epoch 57/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.0302 - val_accuracy: 0.9890\n",
            "Epoch 58/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0306 - accuracy: 0.9908 - val_loss: 0.0324 - val_accuracy: 0.9890\n",
            "Epoch 59/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.0351 - val_accuracy: 0.9890\n",
            "Epoch 60/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0263 - accuracy: 0.9927 - val_loss: 0.0309 - val_accuracy: 0.9890\n",
            "Epoch 61/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0233 - accuracy: 0.9957 - val_loss: 0.0316 - val_accuracy: 0.9890\n",
            "Epoch 62/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0272 - accuracy: 0.9927 - val_loss: 0.0331 - val_accuracy: 0.9890\n",
            "Epoch 63/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0162 - accuracy: 0.9976 - val_loss: 0.0331 - val_accuracy: 0.9890\n",
            "Epoch 64/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.0387 - val_accuracy: 0.9835\n",
            "Epoch 65/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.0294 - val_accuracy: 0.9890\n",
            "Epoch 66/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0206 - accuracy: 0.9963 - val_loss: 0.0350 - val_accuracy: 0.9890\n",
            "Epoch 67/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0198 - accuracy: 0.9957 - val_loss: 0.0386 - val_accuracy: 0.9835\n",
            "Epoch 68/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 0.0400 - val_accuracy: 0.9780\n",
            "Epoch 69/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0223 - accuracy: 0.9945 - val_loss: 0.0298 - val_accuracy: 0.9890\n",
            "Epoch 70/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.0330 - val_accuracy: 0.9890\n",
            "Epoch 71/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.0296 - val_accuracy: 0.9890\n",
            "Epoch 72/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0189 - accuracy: 0.9976 - val_loss: 0.0321 - val_accuracy: 0.9890\n",
            "Epoch 73/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.0290 - val_accuracy: 0.9890\n",
            "Epoch 74/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.0252 - val_accuracy: 0.9890\n",
            "Epoch 75/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.0280 - val_accuracy: 0.9890\n",
            "Epoch 76/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.0240 - val_accuracy: 0.9890\n",
            "Epoch 77/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 0.0290 - val_accuracy: 0.9890\n",
            "Epoch 78/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.0317 - val_accuracy: 0.9890\n",
            "Epoch 79/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0166 - accuracy: 0.9957 - val_loss: 0.0359 - val_accuracy: 0.9835\n",
            "Epoch 80/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0173 - accuracy: 0.9963 - val_loss: 0.0311 - val_accuracy: 0.9890\n",
            "Epoch 81/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.0413 - val_accuracy: 0.9835\n",
            "Epoch 82/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.0320 - val_accuracy: 0.9890\n",
            "Epoch 83/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.0322 - val_accuracy: 0.9890\n",
            "Epoch 84/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0356 - val_accuracy: 0.9835\n",
            "Epoch 85/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0114 - accuracy: 0.9988 - val_loss: 0.0344 - val_accuracy: 0.9835\n",
            "Epoch 86/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0273 - val_accuracy: 0.9890\n",
            "Epoch 87/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 0.0276 - val_accuracy: 0.9890\n",
            "Epoch 88/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0242 - val_accuracy: 0.9890\n",
            "Epoch 89/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 0.0286 - val_accuracy: 0.9890\n",
            "Epoch 90/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9890\n",
            "Epoch 91/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0323 - val_accuracy: 0.9890\n",
            "Epoch 92/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.0286 - val_accuracy: 0.9890\n",
            "Epoch 93/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0294 - val_accuracy: 0.9890\n",
            "Epoch 94/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0089 - accuracy: 0.9994 - val_loss: 0.0326 - val_accuracy: 0.9890\n",
            "Epoch 95/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.0295 - val_accuracy: 0.9890\n",
            "Epoch 96/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.0308 - val_accuracy: 0.9890\n",
            "Epoch 97/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0096 - accuracy: 0.9988 - val_loss: 0.0322 - val_accuracy: 0.9890\n",
            "Epoch 98/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.0303 - val_accuracy: 0.9890\n",
            "Epoch 99/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 0.0262 - val_accuracy: 0.9890\n",
            "Epoch 100/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.0288 - val_accuracy: 0.9890\n",
            "Epoch 101/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.0307 - val_accuracy: 0.9890\n",
            "Epoch 102/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0367 - val_accuracy: 0.9835\n",
            "Epoch 103/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0362 - val_accuracy: 0.9890\n",
            "Epoch 104/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0381 - val_accuracy: 0.9835\n",
            "Epoch 105/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0280 - val_accuracy: 0.9890\n",
            "Epoch 106/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.0371 - val_accuracy: 0.9835\n",
            "Epoch 107/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.0253 - val_accuracy: 0.9890\n",
            "Epoch 108/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.0264 - val_accuracy: 0.9890\n",
            "Epoch 109/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0330 - val_accuracy: 0.9890\n",
            "Epoch 110/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.0193 - val_accuracy: 0.9890\n",
            "Epoch 111/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0081 - accuracy: 0.9988 - val_loss: 0.0296 - val_accuracy: 0.9890\n",
            "Epoch 112/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0077 - accuracy: 0.9994 - val_loss: 0.0298 - val_accuracy: 0.9890\n",
            "Epoch 113/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.0344 - val_accuracy: 0.9890\n",
            "Epoch 114/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.0336 - val_accuracy: 0.9890\n",
            "Epoch 115/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.0238 - val_accuracy: 0.9890\n",
            "Epoch 116/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.0435 - val_accuracy: 0.9835\n",
            "Epoch 117/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.0306 - val_accuracy: 0.9890\n",
            "Epoch 118/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0237 - val_accuracy: 0.9890\n",
            "Epoch 119/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.0297 - val_accuracy: 0.9890\n",
            "Epoch 120/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.0381 - val_accuracy: 0.9890\n",
            "Epoch 121/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.0345 - val_accuracy: 0.9890\n",
            "Epoch 122/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.0279 - val_accuracy: 0.9890\n",
            "Epoch 123/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0311 - val_accuracy: 0.9890\n",
            "Epoch 124/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.0359 - val_accuracy: 0.9890\n",
            "Epoch 125/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0342 - val_accuracy: 0.9890\n",
            "Epoch 126/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.0380 - val_accuracy: 0.9890\n",
            "Epoch 127/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.0337 - val_accuracy: 0.9890\n",
            "Epoch 128/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.0373 - val_accuracy: 0.9890\n",
            "Epoch 129/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9890\n",
            "Epoch 130/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0367 - val_accuracy: 0.9890\n",
            "Epoch 131/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.0286 - val_accuracy: 0.9890\n",
            "Epoch 132/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0071 - accuracy: 0.9963 - val_loss: 0.0355 - val_accuracy: 0.9890\n",
            "Epoch 133/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.0358 - val_accuracy: 0.9890\n",
            "Epoch 134/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.0329 - val_accuracy: 0.9890\n",
            "Epoch 135/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0073 - accuracy: 0.9994 - val_loss: 0.0239 - val_accuracy: 0.9890\n",
            "Epoch 136/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0318 - val_accuracy: 0.9890\n",
            "Epoch 137/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.0278 - val_accuracy: 0.9890\n",
            "Epoch 138/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0327 - val_accuracy: 0.9890\n",
            "Epoch 139/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.0389 - val_accuracy: 0.9890\n",
            "Epoch 140/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0349 - val_accuracy: 0.9890\n",
            "Epoch 141/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0080 - accuracy: 0.9969 - val_loss: 0.0260 - val_accuracy: 0.9890\n",
            "Epoch 142/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0359 - val_accuracy: 0.9890\n",
            "Epoch 143/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9890\n",
            "Epoch 144/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 0.9890\n",
            "Epoch 145/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.0262 - val_accuracy: 0.9890\n",
            "Epoch 146/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0349 - val_accuracy: 0.9890\n",
            "Epoch 147/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0244 - val_accuracy: 0.9890\n",
            "Epoch 148/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9890\n",
            "Epoch 149/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.0341 - val_accuracy: 0.9890\n",
            "Epoch 150/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0341 - val_accuracy: 0.9890\n",
            "Epoch 151/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0307 - val_accuracy: 0.9890\n",
            "Epoch 152/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9890\n",
            "Epoch 153/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9890\n",
            "Epoch 154/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.0369 - val_accuracy: 0.9890\n",
            "Epoch 155/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0463 - val_accuracy: 0.9835\n",
            "Epoch 156/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.0271 - val_accuracy: 0.9890\n",
            "Epoch 157/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0345 - val_accuracy: 0.9890\n",
            "Epoch 158/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.0422 - val_accuracy: 0.9890\n",
            "Epoch 159/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9890\n",
            "Epoch 160/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9890\n",
            "Epoch 161/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.0354 - val_accuracy: 0.9890\n",
            "Epoch 162/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9890\n",
            "Epoch 163/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0397 - val_accuracy: 0.9890\n",
            "Epoch 164/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0358 - val_accuracy: 0.9890\n",
            "Epoch 165/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0355 - val_accuracy: 0.9890\n",
            "Epoch 166/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0341 - val_accuracy: 0.9890\n",
            "Epoch 167/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9890\n",
            "Epoch 168/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9890\n",
            "Epoch 169/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0318 - val_accuracy: 0.9890\n",
            "Epoch 170/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0331 - val_accuracy: 0.9890\n",
            "Epoch 171/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.0294 - val_accuracy: 0.9890\n",
            "Epoch 172/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9890\n",
            "Epoch 173/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 0.9890\n",
            "Epoch 174/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.0274 - val_accuracy: 0.9890\n",
            "Epoch 175/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0380 - val_accuracy: 0.9890\n",
            "Epoch 176/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 0.9890\n",
            "Epoch 177/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 0.9890\n",
            "Epoch 178/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0257 - val_accuracy: 0.9890\n",
            "Epoch 179/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0387 - val_accuracy: 0.9890\n",
            "Epoch 180/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 0.9890\n",
            "Epoch 181/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9890\n",
            "Epoch 182/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9890\n",
            "Epoch 183/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0270 - val_accuracy: 0.9890\n",
            "Epoch 184/500\n",
            "1636/1636 [==============================] - 13s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9890\n",
            "Epoch 185/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.0327 - val_accuracy: 0.9890\n",
            "Epoch 186/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9890\n",
            "Epoch 187/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0297 - val_accuracy: 0.9890\n",
            "Epoch 188/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.0294 - val_accuracy: 0.9890\n",
            "Epoch 189/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9890\n",
            "Epoch 190/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.0295 - val_accuracy: 0.9890\n",
            "Epoch 191/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9890\n",
            "Epoch 192/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0236 - val_accuracy: 0.9890\n",
            "Epoch 193/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9890\n",
            "Epoch 194/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 0.9890\n",
            "Epoch 195/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0293 - val_accuracy: 0.9890\n",
            "Epoch 196/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0238 - val_accuracy: 0.9890\n",
            "Epoch 197/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0374 - val_accuracy: 0.9890\n",
            "Epoch 198/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0337 - val_accuracy: 0.9890\n",
            "Epoch 199/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9890\n",
            "Epoch 200/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9890\n",
            "Epoch 201/500\n",
            "1636/1636 [==============================] - 12s 8ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0293 - val_accuracy: 0.9890\n",
            "Epoch 202/500\n",
            "1600/1636 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAC5LDSTg6kH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare(filename, required_size=(IMG_SIZE, IMG_SIZE)):\n",
        "    # load image from file\n",
        "    pixels = pyplot.imread(filename)\n",
        "    # create the detector, using default weights\n",
        "    detector = MTCNN()\n",
        "    # detect faces in the image\n",
        "    results = detector.detect_faces(pixels)\n",
        "    # extract the bounding box from the first face\n",
        "    x1, y1, width, height = results[0]['box']\n",
        "    x2, y2 = x1 + width+ width//6, y1 + height + height//6\n",
        "\n",
        "    if y1 > height//6:\n",
        "      y1_new = y1 - height//6\n",
        "    else:\n",
        "      y1_new = y1\n",
        "    if x1 > width//6:\n",
        "      x1_new = x1 - width//6\n",
        "    else:\n",
        "      x1_new = x1\n",
        "  \n",
        "    # extract the face\n",
        "    face = pixels[y1_new:y2, x1_new:x2]\n",
        "    # resize pixels to the model size\n",
        "    image = Image.fromarray(face)\n",
        "    image = image.resize(required_size)\n",
        "    face_array = asarray(image)\n",
        "    # face_array = cv2.cvtColor(face_array, cv2.COLOR_BGR2GRAY)\n",
        "    new_array = cv2.resize(face_array, (IMG_SIZE, IMG_SIZE))\n",
        "    pixels = cv2.rectangle(pixels,(x1_new,y1_new),\n",
        "                           (x1 + width+ width//6,y1 + height + height//6),\n",
        "                           (215,255,0),2)\n",
        "    plt.imshow(pixels) \n",
        "    plt.show()\n",
        "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "model = tf.keras.models.load_model(\"CNN2.model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJHYfvrLg6m7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = prepare(\"test_Avicii1.jpg\")\n",
        "prediction = model.predict([image])\n",
        "prediction = list(prediction[0])\n",
        "print(CATEGORIES[prediction.index(max(prediction))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMdyGwFhg6q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = prepare('test_Charlie2.jpg')\n",
        "prediction = model.predict([image])\n",
        "prediction = list(prediction[0])\n",
        "print(CATEGORIES[prediction.index(max(prediction))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_GsjiXHg6t1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = prepare('test_Charlie1.jpg')\n",
        "prediction = model.predict([image])\n",
        "prediction = list(prediction[0])\n",
        "print(CATEGORIES[prediction.index(max(prediction))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkS6Z9Srg6po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = prepare('test_Den2.jpg')\n",
        "prediction = model.predict([image])\n",
        "prediction = list(prediction[0])\n",
        "print(CATEGORIES[prediction.index(max(prediction))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eXlIEHdg6f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = prepare('test_Den3.jpg')\n",
        "prediction = model.predict([image])\n",
        "prediction = list(prediction[0])\n",
        "print(CATEGORIES[prediction.index(max(prediction))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxvKLAQJTtT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = prepare(\"test_Avicii2.jpg\")\n",
        "prediction = model.predict([image])\n",
        "prediction = list(prediction[0])\n",
        "print(CATEGORIES[prediction.index(max(prediction))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv-6Lo-tiJ23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = prepare('test_Avicii4.jpg')\n",
        "prediction = model.predict([image])\n",
        "prediction = list(prediction[0])\n",
        "print(CATEGORIES[prediction.index(max(prediction))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOUuxndvjLic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = prepare('test_Avicii5.jpg')\n",
        "prediction = model.predict([image])\n",
        "prediction = list(prediction[0])\n",
        "print(CATEGORIES[prediction.index(max(prediction))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWt9jCIixwFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = prepare('test_Den5.jpg')\n",
        "prediction = model.predict([image])\n",
        "prediction = list(prediction[0])\n",
        "print(CATEGORIES[prediction.index(max(prediction))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOiWMGGHyFq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"model.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2ptQ_166H6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip CNN2.model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw9O1oan6hYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('CNN.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-2jd4pl67Mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}